{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0b2d0222",
   "metadata": {},
   "source": [
    "# Exemplo de estimativa de similaridade entre usando python"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b7af2b6",
   "metadata": {},
   "source": [
    "## Instalação das bibliotecas necessárias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dbbb2b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "$ pip install -U scikit-learn pandas nltk matplotlib-venn numpy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd0b1ab9",
   "metadata": {},
   "source": [
    "## Exemplo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3a15fc8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib_venn import venn2\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "from nltk.stem.wordnet import WordNetLemmatizer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27ac32af",
   "metadata": {},
   "source": [
    "### Tokenização"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36ed74a8",
   "metadata": {},
   "source": [
    "Simplificando, é dividir algum texto em tokens, esses tokens normalmente são as palavras contidas no texto, se um texto tem 10 palavras, possivelmente (depende da metodologia) terá 10 tokens. Também podem ser divididos por letras ou conjunto de palavras. A metodologia fica a critério de quem fará os tokens."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3aff4a25",
   "metadata": {},
   "source": [
    "### Unigrams"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94bc4d84",
   "metadata": {},
   "source": [
    "São tokens com apenas uma palavra em cada token. Exemplo de lista de tokens com unigram para a seguinte frase:\n",
    "\n",
    "\"Deus é bom o tempo todo\" - {\"deus\",\"bom\", \"tempo\", \"todo\"}.\n",
    "\n",
    "Neste caso, não consideramos palavras com apenas um caractere, também não contem os acentos e todas as palavras estão em minúsculo."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bee6028f",
   "metadata": {},
   "source": [
    "### Bigrams"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60c62ccb",
   "metadata": {},
   "source": [
    "Como o nome já sugere, são tokens tendo duas palavras em cada token, sendo a segunda palavra sempre sequência da terceira. E a partir do Bigram podemos ter trigrams, e quantos n-grams quisermos, mas geralmente só é utilizado até \"3 grams\". Exemplo de lista de tokens com bigram.\n",
    "\n",
    "\"Deus é bom o tempo todo\" - {\"deus bom\", \"bom tempo\", \"tempo todo\"}'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "001845d7",
   "metadata": {},
   "source": [
    "### Tokenizando com Unigrams e Bigrams"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d3e7194",
   "metadata": {},
   "source": [
    "\"Deus é bom o tempo todo\"\n",
    "\n",
    "{\"deus\",\"bom\",\"tempo\",\"todo\",\"deus bom\",\"bom tempo\",\"tempo todo\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "56f407ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "t1 = \"era uma vez um lugarzinho no meio do nada com sabor de chocolate e cheiro de terra molhada\"\n",
    "t2 = \"era uma vez a riqueza contra a simplicidade, uma mostrando para a outra quem dava mais felicidade\"\n",
    "t3 = \"pra gente ser feliz, temos que cultivar as nossas amizades, os amigos de verdade, temos que mergulhar na própria fantasia na nossa liberdade\"\n",
    "\n",
    "vect = CountVectorizer(analyzer = \"word\", ngram_range=(1,2))\n",
    "\n",
    "vocab = vect.fit([t1,t2,t3])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d01f49a",
   "metadata": {},
   "source": [
    "Para mostrar todas a palavras e bigramas contidos no vocabulário"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d5bb713e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'era': 24,\n",
       " 'uma': 85,\n",
       " 'vez': 90,\n",
       " 'um': 83,\n",
       " 'lugarzinho': 34,\n",
       " 'no': 50,\n",
       " 'meio': 38,\n",
       " 'do': 22,\n",
       " 'nada': 48,\n",
       " 'com': 10,\n",
       " 'sabor': 73,\n",
       " 'de': 18,\n",
       " 'chocolate': 8,\n",
       " 'cheiro': 6,\n",
       " 'terra': 81,\n",
       " 'molhada': 42,\n",
       " 'era uma': 25,\n",
       " 'uma vez': 87,\n",
       " 'vez um': 92,\n",
       " 'um lugarzinho': 84,\n",
       " 'lugarzinho no': 35,\n",
       " 'no meio': 51,\n",
       " 'meio do': 39,\n",
       " 'do nada': 23,\n",
       " 'nada com': 49,\n",
       " 'com sabor': 11,\n",
       " 'sabor de': 74,\n",
       " 'de chocolate': 19,\n",
       " 'chocolate cheiro': 9,\n",
       " 'cheiro de': 7,\n",
       " 'de terra': 20,\n",
       " 'terra molhada': 82,\n",
       " 'riqueza': 71,\n",
       " 'contra': 12,\n",
       " 'simplicidade': 77,\n",
       " 'mostrando': 43,\n",
       " 'para': 60,\n",
       " 'outra': 58,\n",
       " 'quem': 69,\n",
       " 'dava': 16,\n",
       " 'mais': 36,\n",
       " 'felicidade': 28,\n",
       " 'vez riqueza': 91,\n",
       " 'riqueza contra': 72,\n",
       " 'contra simplicidade': 13,\n",
       " 'simplicidade uma': 78,\n",
       " 'uma mostrando': 86,\n",
       " 'mostrando para': 44,\n",
       " 'para outra': 61,\n",
       " 'outra quem': 59,\n",
       " 'quem dava': 70,\n",
       " 'dava mais': 17,\n",
       " 'mais felicidade': 37,\n",
       " 'pra': 62,\n",
       " 'gente': 31,\n",
       " 'ser': 75,\n",
       " 'feliz': 29,\n",
       " 'temos': 79,\n",
       " 'que': 66,\n",
       " 'cultivar': 14,\n",
       " 'as': 4,\n",
       " 'nossas': 54,\n",
       " 'amizades': 2,\n",
       " 'os': 56,\n",
       " 'amigos': 0,\n",
       " 'verdade': 88,\n",
       " 'mergulhar': 40,\n",
       " 'na': 45,\n",
       " 'própria': 64,\n",
       " 'fantasia': 26,\n",
       " 'nossa': 52,\n",
       " 'liberdade': 33,\n",
       " 'pra gente': 63,\n",
       " 'gente ser': 32,\n",
       " 'ser feliz': 76,\n",
       " 'feliz temos': 30,\n",
       " 'temos que': 80,\n",
       " 'que cultivar': 67,\n",
       " 'cultivar as': 15,\n",
       " 'as nossas': 5,\n",
       " 'nossas amizades': 55,\n",
       " 'amizades os': 3,\n",
       " 'os amigos': 57,\n",
       " 'amigos de': 1,\n",
       " 'de verdade': 21,\n",
       " 'verdade temos': 89,\n",
       " 'que mergulhar': 68,\n",
       " 'mergulhar na': 41,\n",
       " 'na própria': 47,\n",
       " 'própria fantasia': 65,\n",
       " 'fantasia na': 27,\n",
       " 'na nossa': 46,\n",
       " 'nossa liberdade': 53}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab.vocabulary_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3c0418a",
   "metadata": {},
   "source": [
    "O número ao lado de cada token, é o número de referência."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50496bc2",
   "metadata": {},
   "source": [
    "## Matriz de Tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89e52084",
   "metadata": {},
   "source": [
    "O método _fit_transform_ cria matrizes, onde cada coluna referencia um token, e cada linha seria um tipo de evento, no nosso caso são frases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e2f8be71",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 0 0 0 0 0 1 1 1 1 1 1 0 0 0 0 0 0 2 1 1 0 1 1 1 1 0 0 0 0 0 0 0 0 1 1\n",
      "  0 0 1 1 0 0 1 0 0 0 0 0 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "  0 1 1 0 0 0 0 0 0 1 1 1 1 1 0 1 0 0 1 0 1]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 1 1 0 0 0 0 0 0 1 1 0 0 1 0 0 0 0 0 0 0\n",
      "  1 1 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 0 0 0 0 0 0 0 1 1 1\n",
      "  1 0 0 0 0 1 1 0 0 0 0 0 0 2 1 1 0 0 1 1 0]\n",
      " [1 1 1 1 1 1 0 0 0 0 0 0 0 0 1 1 0 0 1 0 0 1 0 0 0 0 1 1 0 1 1 1 1 1 0 0\n",
      "  0 0 0 0 1 1 0 0 0 2 1 1 0 0 0 0 1 1 1 1 1 1 0 0 0 0 1 1 1 1 2 1 1 0 0 0\n",
      "  0 0 0 1 1 0 0 2 2 0 0 0 0 0 0 0 1 1 0 0 0]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'era': 24,\n",
       " 'uma': 85,\n",
       " 'vez': 90,\n",
       " 'um': 83,\n",
       " 'lugarzinho': 34,\n",
       " 'no': 50,\n",
       " 'meio': 38,\n",
       " 'do': 22,\n",
       " 'nada': 48,\n",
       " 'com': 10,\n",
       " 'sabor': 73,\n",
       " 'de': 18,\n",
       " 'chocolate': 8,\n",
       " 'cheiro': 6,\n",
       " 'terra': 81,\n",
       " 'molhada': 42,\n",
       " 'era uma': 25,\n",
       " 'uma vez': 87,\n",
       " 'vez um': 92,\n",
       " 'um lugarzinho': 84,\n",
       " 'lugarzinho no': 35,\n",
       " 'no meio': 51,\n",
       " 'meio do': 39,\n",
       " 'do nada': 23,\n",
       " 'nada com': 49,\n",
       " 'com sabor': 11,\n",
       " 'sabor de': 74,\n",
       " 'de chocolate': 19,\n",
       " 'chocolate cheiro': 9,\n",
       " 'cheiro de': 7,\n",
       " 'de terra': 20,\n",
       " 'terra molhada': 82,\n",
       " 'riqueza': 71,\n",
       " 'contra': 12,\n",
       " 'simplicidade': 77,\n",
       " 'mostrando': 43,\n",
       " 'para': 60,\n",
       " 'outra': 58,\n",
       " 'quem': 69,\n",
       " 'dava': 16,\n",
       " 'mais': 36,\n",
       " 'felicidade': 28,\n",
       " 'vez riqueza': 91,\n",
       " 'riqueza contra': 72,\n",
       " 'contra simplicidade': 13,\n",
       " 'simplicidade uma': 78,\n",
       " 'uma mostrando': 86,\n",
       " 'mostrando para': 44,\n",
       " 'para outra': 61,\n",
       " 'outra quem': 59,\n",
       " 'quem dava': 70,\n",
       " 'dava mais': 17,\n",
       " 'mais felicidade': 37,\n",
       " 'pra': 62,\n",
       " 'gente': 31,\n",
       " 'ser': 75,\n",
       " 'feliz': 29,\n",
       " 'temos': 79,\n",
       " 'que': 66,\n",
       " 'cultivar': 14,\n",
       " 'as': 4,\n",
       " 'nossas': 54,\n",
       " 'amizades': 2,\n",
       " 'os': 56,\n",
       " 'amigos': 0,\n",
       " 'verdade': 88,\n",
       " 'mergulhar': 40,\n",
       " 'na': 45,\n",
       " 'própria': 64,\n",
       " 'fantasia': 26,\n",
       " 'nossa': 52,\n",
       " 'liberdade': 33,\n",
       " 'pra gente': 63,\n",
       " 'gente ser': 32,\n",
       " 'ser feliz': 76,\n",
       " 'feliz temos': 30,\n",
       " 'temos que': 80,\n",
       " 'que cultivar': 67,\n",
       " 'cultivar as': 15,\n",
       " 'as nossas': 5,\n",
       " 'nossas amizades': 55,\n",
       " 'amizades os': 3,\n",
       " 'os amigos': 57,\n",
       " 'amigos de': 1,\n",
       " 'de verdade': 21,\n",
       " 'verdade temos': 89,\n",
       " 'que mergulhar': 68,\n",
       " 'mergulhar na': 41,\n",
       " 'na própria': 47,\n",
       " 'própria fantasia': 65,\n",
       " 'fantasia na': 27,\n",
       " 'na nossa': 46,\n",
       " 'nossa liberdade': 53}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# t1 e t2 são nossos dois textos, e aplicamos a real transform!\n",
    "texts = vect.fit_transform([t1,t2,t3])\n",
    "texts_array = texts.toarray() #Transformando em array para olhar a matriz\n",
    "print(texts_array)\n",
    "vocab.vocabulary_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8777beb",
   "metadata": {},
   "source": [
    "Os números presentes na matriz mostram quantas vezes determinado token apareceu em nossas frases. Em textos maiores, ou projetos maiores, é comum vermos grandes matrizes cheias de zero."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37ae49ab",
   "metadata": {},
   "source": [
    "## Bora calcular!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fca0a8c8",
   "metadata": {},
   "source": [
    "A primeira coisa que precisamos fazer é calcular a intersecção entre as matrizes, e para isso pegamos o valor mínimo de cada coluna, por exemplo, se o valor da primeira linha da quarta coluna é 1, e da segunda linha for 0, então o valor mínimo será 0, não havendo, portando, ali, uma intersecção."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9fd542c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0], dtype=int64)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "intersection_list = np.amin(texts_array, axis = 0) # calculando a intersecção\n",
    "intersection_list"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ead288d0",
   "metadata": {},
   "source": [
    "Depois devemos fazer a soma de todas as intersecções"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a42b2008",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum = np.sum(intersection_list)\n",
    "sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0165eef2",
   "metadata": {},
   "outputs": [],
   "source": [
    "x1 = t1\n",
    "x2 = t2\n",
    "x3 = t3\n",
    "\n",
    "vect1 = CountVectorizer(analyzer = 'word', ngram_range = (1,2))\n",
    "vect2 = CountVectorizer(analyzer = 'word', ngram_range = (1,2))\n",
    "\n",
    "vecx1 = vect1.fit([x1])\n",
    "vecx2 = vect2.fit([x2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7b4c163",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
